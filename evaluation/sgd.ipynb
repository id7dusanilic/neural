{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56159e29-639d-46e5-9741-bb0287c5a239",
   "metadata": {},
   "source": [
    "# Evaluating performance of the SGD alghorithm\n",
    "In this example, a classic neural network is created using the `neural` framework. This network is than trained on the MNIST data set of hand-written digits using the SGD (*Stochastic Gradient Descent*) algorithm. This notebook serves as an evaluation of SGD performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc306c-b6bb-478e-9976-71f22b5ef4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f57913-9c55-4535-9f0b-23e5efb8b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b25f3b5-c9f3-4986-88a7-39d758166437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39814444-6910-443d-8337-da33925ed4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from neural import MNIST, Tensor, nn, optim\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650fee3-7ebc-46f2-bc46-1464832c98a4",
   "metadata": {},
   "source": [
    "## Importing MNIST training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fb65e-283b-4296-93ce-d4e3e92259e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training set\n",
    "allTrainImages, allTrainLabels = MNIST.get(\"train\")\n",
    "# Images are normalized, all values are in the range [-1, 1]\n",
    "allTrainImages = normalize(allTrainImages, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b65894-3fb2-4857-9353-91a3d6e208f2",
   "metadata": {},
   "source": [
    "## Defining the Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d600bae-8f1c-482c-9831-0ba5af7d1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.logSoftmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.logSoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01baffd-9f55-4a1a-824f-94017d0a2aa8",
   "metadata": {},
   "source": [
    "## Choosing training criterion (loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72397405-eaac-4aac-8692-37018fafb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "reduction = \"mean\"\n",
    "criterion = nn.NLLLoss(reduction=reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8cac63-8a1a-405a-bad6-b277fb5b4710",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Choosing training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af83b11-9a33-4854-a10b-66d1828f28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining sweep parameters\n",
    "lrs = [0.001, 0.01, 0.03]\n",
    "momentums = [0.0, 0.5,0.9]\n",
    "batchSizes = [10, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18f27fd-bc2c-4e63-be16-74a9878d05f4",
   "metadata": {},
   "source": [
    "## Training for each parameter combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fa6ec7-5f90-497a-a42e-b668a5afd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numConfigs = np.prod([len(lrs), len(momentums), len(batchSizes)])\n",
    "configs = product(lrs, momentums, batchSizes)\n",
    "\n",
    "print(f\"Total number of configurations: {numConfigs}\")\n",
    "for j, (lr, momentum, batchSize) in enumerate(configs):\n",
    "    model = Network()    \n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=lr,\n",
    "        momentum=momentum)\n",
    "    \n",
    "    numBatches = allTrainImages.shape[0] // batchSize\n",
    "    numTraining = int(numBatches * batchSize)\n",
    "\n",
    "    trainImages = allTrainImages[:numTraining].reshape(numBatches, -1, allTrainImages.shape[-2], allTrainImages.shape[-1])\n",
    "    trainLabels = allTrainLabels[:numTraining].reshape(numBatches, -1)\n",
    "        \n",
    "    lossTrack = np.zeros(numBatches)\n",
    "    startTime = time.time()\n",
    "    for i, (images, labels) in enumerate(zip(trainImages, trainLabels)):\n",
    "        images = images.reshape(images.shape[0], -1)\n",
    "        optimizer.zeroGrad()\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossTrack[i] = loss.item()\n",
    "    else:\n",
    "        endTime = time.time()\n",
    "        print(f\"Finished configuration {j} in {endTime - startTime:.2f}s\")\n",
    "        np.savetxt(f\"lossTrack_{lr}_{momentum}_{batchSize}\", lossTrack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5474ea2-7571-4957-aa1a-9fa63091d61c",
   "metadata": {},
   "source": [
    "## Convergence rate vs `momentum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f39f830-3cde-41d3-bfb8-ba433a8d16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose batchSize and lr for the plot\n",
    "batchSize = batchSizes[2]\n",
    "lr = lrs[0]\n",
    "\n",
    "# Plot data\n",
    "plots = [(np.loadtxt(f\"lossTrack_{lr}_{momentum}_{batchSize}\"), batchSize, \n",
    "          f\"Learning rate: {lr}\\nMomentum: {momentum}\\nBatch size: {batchSize}\") for momentum in momentums]  \n",
    "\n",
    "plotLossTrack(plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca1e4d-3e9c-4ab8-91e5-fd696e310fc3",
   "metadata": {},
   "source": [
    "## Convergence rate vs batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073d5e79-9771-4063-b26f-6a9e4c5dd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose momentum and lr for the plot\n",
    "momentum = momentums[0]\n",
    "lr = lrs[2]\n",
    "\n",
    "# Plot data\n",
    "plots = [(np.loadtxt(f\"lossTrack_{lr}_{momentum}_{batchSize}\"), batchSize, \n",
    "          f\"Learning rate: {lr}\\nMomentum: {momentum}\\nBatch size: {batchSize}\") for batchSize in batchSizes]  \n",
    "\n",
    "plotLossTrack(plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb49094-bd9e-47cb-8dd2-848a75f76d6e",
   "metadata": {},
   "source": [
    "## Convergence rate vs learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d199ae-3cec-497a-96d9-fe25d741e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = batchSizes[1]\n",
    "momentum = momentums[0]\n",
    "\n",
    "plots = [(np.loadtxt(f\"lossTrack_{lr}_{momentum}_{batchSize}\"), batchSize, \n",
    "          f\"Learning rate: {lr}\\nMomentum: {momentum}\\nBatch size: {batchSize}\") for lr in lrs]  \n",
    "\n",
    "plotLossTrack(plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce54f7-25c4-4191-b0b3-320fa7b9b91c",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13972d68-49b7-45e7-8cf2-91b6f7c26252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image iterator\n",
    "imgIter = iter(allTrainImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d46ffd-27e9-4087-8511-7081be879cc1",
   "metadata": {},
   "source": [
    "Run the cell bellow multiple times to check model performance for different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e5e76-c154-4df3-bebf-c802ff6f7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(imgIter)\n",
    "img_ = img.reshape(1, -1)\n",
    "\n",
    "logps = model(img_)\n",
    "# Output of the network are log-probabilities\n",
    "ps = np.exp(logps)\n",
    "\n",
    "showMNIST(img.squeeze(), ps.squeeze())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
